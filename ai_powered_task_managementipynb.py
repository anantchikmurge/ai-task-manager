# -*- coding: utf-8 -*-
"""AI_POWERED_TASK_MANAGEMENTipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1z556FW2aR3DaKsm8wXEYeDrc7k3Qtx4q

Data Collection, EDA, and NLP Preprocessing
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from nltk.stem import PorterStemmer
from wordcloud import WordCloud

df = pd.read_csv("synthetic_task_dataset.csv")

stopwords = {'a','an','the','and','or','but','if','while','with','at','by','for','to','in','on','of','this','that',
             'is','are','was','were','be','been','has','have','had','it','its','as','from','not'}
stemmer = PorterStemmer()

def preprocess(text):
    tokens = text.lower().split()
    return " ".join([stemmer.stem(w) for w in tokens if w not in stopwords])

df["Cleaned_Description"] = df["Description"].apply(preprocess)

plt.figure(figsize=(14, 6))
plt.subplot(1, 2, 1)
sns.countplot(x="Priority", data=df, palette="coolwarm")
plt.title("Priority Distribution")

plt.subplot(1, 2, 2)
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(" ".join(df["Cleaned_Description"]))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.title("Word Cloud of Cleaned Descriptions")

plt.tight_layout()
plt.show()

df.to_csv("preprocessed_task_dataset.csv", index=False)

"""Feature Extraction and Task Classification"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import LinearSVC
from sklearn.metrics import classification_report

df = pd.read_csv("preprocessed_task_dataset.csv")

vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(df["Cleaned_Description"])
y = df["Category"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

nb = MultinomialNB().fit(X_train, y_train)
print("Naive Bayes:\n", classification_report(y_test, nb.predict(X_test)))

svm = LinearSVC().fit(X_train, y_train)
print("SVM:\n", classification_report(y_test, svm.predict(X_test)))

"""Priority Prediction and Workload Balancing

> Add blockquote


"""

import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import classification_report
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder
import scipy

# Load data
df = pd.read_csv("preprocessed_task_dataset.csv")

# Encode 'Assigned To' and 'Priority' as numbers
le_user = LabelEncoder()
df["UserCode"] = le_user.fit_transform(df["Assigned To"])

le_priority = LabelEncoder()
df["PriorityEncoded"] = le_priority.fit_transform(df["Priority"])  # Encode labels like 'High', 'Low'

# TF-IDF + usercode feature
vectorizer = TfidfVectorizer()
desc_tfidf = vectorizer.fit_transform(df["Cleaned_Description"])
X = scipy.sparse.hstack([desc_tfidf, df[["UserCode"]]])

# Target label (encoded)
y = df["PriorityEncoded"]

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Random Forest Model
rf = RandomForestClassifier().fit(X_train, y_train)
print("Random Forest:\n", classification_report(y_test, rf.predict(X_test), target_names=le_priority.classes_))

# XGBoost Model (now works)
xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
xgb.fit(X_train, y_train)
print("XGBoost:\n", classification_report(y_test, xgb.predict(X_test), target_names=le_priority.classes_))

# GridSearchCV (optional tuning)
param_grid = {
    'n_estimators': [50, 100],
    'max_depth': [5, 10]
}
gs = GridSearchCV(RandomForestClassifier(), param_grid, cv=3)
gs.fit(X_train, y_train)
print("Best Random Forest Params:", gs.best_params_)

""" Final Dashboard"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv("preprocessed_task_dataset.csv")

plt.figure(figsize=(12, 8))

plt.subplot(2, 2, 1)
sns.countplot(x="Priority", data=df, palette="magma")
plt.title("Task Priority")

plt.subplot(2, 2, 2)
sns.countplot(x="Category", data=df, palette="viridis")
plt.title("Task Category")

plt.subplot(2, 2, 3)
sns.countplot(x="Status", data=df, palette="cool")
plt.title("Task Status")

plt.tight_layout()
plt.show()

summary = df.groupby(["Assigned To", "Priority"]).size().unstack(fill_value=0)
summary.to_csv("user_priority_summary.csv")